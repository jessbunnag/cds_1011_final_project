{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/conda/1011_project/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from encoder import *\n",
    "from AttnDecoder import * \n",
    "from seq2seq import *\n",
    "\n",
    "from build_dataset import *\n",
    "from inference import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "from beamsearch import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set whether or not model is pretrained\n",
    "model_pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "main_data_path = \"data/processed\"\n",
    "\n",
    "train_file_path = {\n",
    "    'source': f\"{main_data_path}/src-train.txt\",\n",
    "    'target': f\"{main_data_path}/tgt-train.txt\"\n",
    "}\n",
    "\n",
    "test_file_path = {\n",
    "    'source': f\"{main_data_path}/src-test.txt\",\n",
    "    'target': f\"{main_data_path}/tgt-test.txt\"\n",
    "}\n",
    "\n",
    "dev_file_path = {\n",
    "    'source': f\"{main_data_path}/src-dev.txt\",\n",
    "    'target': f\"{main_data_path}/tgt-dev.txt\"\n",
    "}\n",
    "\n",
    "# build vocab with train data only \n",
    "vocab = build_train_vocab(train_file_path)\n",
    "\n",
    "# build datasets for all train, test, dev\n",
    "datasets = {\n",
    "    'train': QAPair(train_file_path, vocab),\n",
    "    'test': QAPair(test_file_path, vocab),\n",
    "    'dev': QAPair(dev_file_path, vocab),\n",
    "}\n",
    "\n",
    "# build dataloaders\n",
    "batch_size = 64\n",
    "dataloaders = {}\n",
    "for split, dataset in datasets.items():\n",
    "    dataloaders[split] = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=partial(pad_collate_fn, pad_token=dataset.pad_idx)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load parsed GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "pretrained_vectors = {\n",
    "    'enc': torch.load(f'embeddings/encoder_emb_{embed_size}.pt').float(),\n",
    "    'dec': torch.load(f'embeddings/decoder_emb_{embed_size}.pt').float()\n",
    "}\n",
    "\n",
    "# input_size = len(train_dataset.answer_vocab) \n",
    "output_size = len(vocab['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Define train and eval steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch, model, optimizer, criterion, device):\n",
    "    input = batch.source_vecs.to(device) \n",
    "    inputs_len = batch.source_lens.to(device)\n",
    "    target = batch.target_vecs.to(device)\n",
    "    target_len = batch.target_lens.to(device) \n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    dec_log_probs, dec_hidden, attn_scores_mat = model(input, target, inputs_len, target_len)\n",
    "\n",
    "    # scores = s2s_output.view(-1, s2s_output.size(-1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(dec_log_probs.transpose(1, 2), target)\n",
    "    loss.backward()\n",
    "    # clip gradients\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0, norm_type=2)\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    # return the attention scores at the last time step\n",
    "    return loss.item(), dec_log_probs, attn_scores_mat\n",
    "\n",
    "def eval_step(batch, model, criterion, device):\n",
    "    input = batch.source_vecs.to(device) \n",
    "    inputs_len = batch.source_lens.to(device)\n",
    "    target = batch.target_vecs.to(device)\n",
    "    target_len = batch.target_lens.to(device) \n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    dec_log_probs, dec_hidden, attn_scores_mat = model(input, target, inputs_len, target_len)\n",
    "\n",
    "    # scores = s2s_output.view(-1, s2s_output.size(-1))\n",
    "    \n",
    "    loss = criterion(dec_log_probs.transpose(1, 2), target)\n",
    "\n",
    "    # return the attention scores at the last time step\n",
    "    return loss.item(), dec_log_probs, attn_scores_mat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN LOOP \n",
    "\n",
    "if not model_pretrained:\n",
    "    # initial learning rate\n",
    "    lr = 1.0\n",
    "    # initialize the model, optimizer, and criterion\n",
    "    seq2seq = Seq2Seq(pretrained_vectors, hidden_size=600, output_size=output_size)\n",
    "    optimizer = torch.optim.SGD(seq2seq.parameters(), lr=lr)\n",
    "    criterion = nn.NLLLoss(ignore_index=datasets['train'].pad_idx)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    seq2seq.to(device)\n",
    "\n",
    "    plot_cache = {}\n",
    "    plot_cache['train'] = []\n",
    "    plot_cache['test'] = []\n",
    "\n",
    "    # halve lr at epoch 8\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.5) \n",
    "\n",
    "    NUM_EPOCHS = 15\n",
    "    for epoch in tqdm(range(NUM_EPOCHS)):    \n",
    "        # train \n",
    "        train_losses = []\n",
    "        for i, data in tqdm(enumerate(dataloaders['train']), leave=False):\n",
    "            curr_loss, dec_log_probs, attn_scores_mat = train_step(data, seq2seq, optimizer, criterion, device)\n",
    "\n",
    "            train_losses.append(curr_loss)\n",
    "\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        print(f'Train loss after epoch {epoch+1} = {avg_train_loss}')\n",
    "\n",
    "        # eval \n",
    "        test_losses = []\n",
    "        with torch.no_grad():\n",
    "            for i, data in tqdm(enumerate(dataloaders['test']), leave=False):\n",
    "                curr_loss, dec_log_probs, attn_scores_mat = eval_step(data, seq2seq, criterion, device)\n",
    "\n",
    "                test_losses.append(curr_loss)\n",
    "\n",
    "            avg_test_loss = np.mean(test_losses)\n",
    "            print(f'Test loss after epoch {epoch+1} = {avg_test_loss}')\n",
    "\n",
    "        plot_cache['train'].append(avg_train_loss)\n",
    "        plot_cache['test'].append(avg_test_loss)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # save the model state\n",
    "    torch.save({'state_dict': seq2seq.state_dict(), 'plot_cache': plot_cache}, 'trained_seq2seq_statedict.pt')\n",
    "else:\n",
    "    # reload the model\n",
    "    seq2seq = Seq2Seq(pretrained_vectors, hidden_size=600, output_size=output_size)\n",
    "    criterion = nn.NLLLoss(ignore_index=datasets['train'].pad_idx)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seq2seq.to(device)\n",
    "\n",
    "    checkpoint = torch.load('trained_seq2seq_statedict.pt')\n",
    "    seq2seq.load_state_dict(checkpoint['state_dict'])\n",
    "    plot_cache = checkpoint['plot_cache']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target question: ['how', 'many', 'people', 'were', 'left', 'homeless', 'because', 'of', 'the', 'earthquake', '?']\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134]\n",
      "Sum log prob -14.964481353759766\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[ 0.0332, -0.2879, -0.0891,  ...,  0.1773, -0.3392, -0.0314]],\n",
      "\n",
      "        [[-0.6489,  0.1066, -0.7120,  ...,  0.6436, -0.6028,  0.4995]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers']\n",
      "Prefix [1, 6207]\n",
      "Sum log prob -14.166219711303711\n",
      "Decoder output tensor([[6207]], device='cuda:0')\n",
      "Decoder hidden tensor([[[ 0.0332, -0.2879, -0.0891,  ...,  0.1773, -0.3392, -0.0314]],\n",
      "\n",
      "        [[-0.6489,  0.1066, -0.7120,  ...,  0.6436, -0.6028,  0.4995]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs']\n",
      "Prefix [1, 6215]\n",
      "Sum log prob -13.877104759216309\n",
      "Decoder output tensor([[6215]], device='cuda:0')\n",
      "Decoder hidden tensor([[[ 0.0332, -0.2879, -0.0891,  ...,  0.1773, -0.3392, -0.0314]],\n",
      "\n",
      "        [[-0.6489,  0.1066, -0.7120,  ...,  0.6436, -0.6028,  0.4995]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'appalachians']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134]\n",
      "Sum log prob -15.985390543937683\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0934, -0.2998,  0.1657,  ...,  0.1530, -0.2206, -0.1528]],\n",
      "\n",
      "        [[-0.5903,  0.2568, -0.7184,  ...,  0.7153, -0.6323,  0.1270]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers']\n",
      "Prefix [1, 2134, 2134]\n",
      "Sum log prob -15.620332479476929\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[ 0.0031, -0.2448,  0.0719,  ...,  0.0367, -0.3223, -0.4299]],\n",
      "\n",
      "        [[-0.5908,  0.3845, -0.7246,  ...,  0.7015, -0.6494,  0.0772]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2573]\n",
      "Sum log prob -15.732989192008972\n",
      "Decoder output tensor([[2573]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0934, -0.2998,  0.1657,  ...,  0.1530, -0.2206, -0.1528]],\n",
      "\n",
      "        [[-0.5903,  0.2568, -0.7184,  ...,  0.7153, -0.6323,  0.1270]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'kilometers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134]\n",
      "Sum log prob -16.183019176125526\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0361, -0.2282,  0.0067,  ...,  0.0558, -0.2395, -0.3203]],\n",
      "\n",
      "        [[-0.5760,  0.2629, -0.7159,  ...,  0.6713, -0.6155,  0.1896]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134]\n",
      "Sum log prob -15.788331121206284\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0355, -0.2385,  0.0347,  ...,  0.0751, -0.2307, -0.3239]],\n",
      "\n",
      "        [[-0.5927,  0.2832, -0.7119,  ...,  0.6779, -0.6413,  0.2495]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2573, 2573]\n",
      "Sum log prob -16.02015322446823\n",
      "Decoder output tensor([[2573]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0723, -0.2237,  0.1860,  ...,  0.0194,  0.0304, -0.4114]],\n",
      "\n",
      "        [[-0.5798,  0.1333, -0.7148,  ...,  0.7308, -0.6180, -0.5674]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'kilometers', 'kilometers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2573, 2573, 2573]\n",
      "Sum log prob -17.761501371860504\n",
      "Decoder output tensor([[2573]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0796, -0.2241,  0.1222,  ..., -0.0199,  0.0612, -0.3980]],\n",
      "\n",
      "        [[-0.5352,  0.0925, -0.6779,  ...,  0.7023, -0.5293, -0.4615]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'kilometers', 'kilometers', 'kilometers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -16.411918371915817\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0266, -0.2386,  0.0049,  ...,  0.0312, -0.2150, -0.3418]],\n",
      "\n",
      "        [[-0.5644,  0.3207, -0.7042,  ...,  0.6729, -0.6342,  0.2768]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134]\n",
      "Sum log prob -16.85870762169361\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0289, -0.2393,  0.0097,  ...,  0.0290, -0.2120, -0.3389]],\n",
      "\n",
      "        [[-0.5628,  0.3183, -0.7000,  ...,  0.6746, -0.6346,  0.2679]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213]\n",
      "Sum log prob -19.316006153821945\n",
      "Decoder output tensor([[2213]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0285, -0.2403,  0.0105,  ...,  0.0325, -0.2128, -0.3417]],\n",
      "\n",
      "        [[-0.5738,  0.3044, -0.7050,  ...,  0.6694, -0.6416,  0.2579]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -16.864006489515305\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0285, -0.2403,  0.0105,  ...,  0.0325, -0.2128, -0.3417]],\n",
      "\n",
      "        [[-0.5738,  0.3044, -0.7050,  ...,  0.6694, -0.6416,  0.2579]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -17.31217809021473\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0288, -0.2400,  0.0093,  ...,  0.0318, -0.2120, -0.3418]],\n",
      "\n",
      "        [[-0.5724,  0.3009, -0.7046,  ...,  0.6677, -0.6402,  0.2640]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92]\n",
      "Sum log prob -19.32288312120363\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.1588, -0.2280,  0.0933,  ..., -0.1320,  0.1261, -0.2329]],\n",
      "\n",
      "        [[-0.6109,  0.2040, -0.7081,  ...,  0.3533, -0.6562,  0.6308]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -17.36667338013649\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0275, -0.2404,  0.0105,  ...,  0.0320, -0.2122, -0.3418]],\n",
      "\n",
      "        [[-0.5706,  0.3054, -0.7043,  ...,  0.6688, -0.6389,  0.2601]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -17.821326091885567\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0274, -0.2404,  0.0104,  ...,  0.0317, -0.2120, -0.3419]],\n",
      "\n",
      "        [[-0.5700,  0.3049, -0.7039,  ...,  0.6689, -0.6385,  0.2583]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92]\n",
      "Sum log prob -19.85207175416872\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-2.9836e-01,  5.0303e-04,  1.4563e-01,  ..., -3.8836e-01,\n",
      "           4.2521e-01, -1.1523e-01]],\n",
      "\n",
      "        [[-6.1646e-01,  1.1872e-01, -7.1922e-01,  ..., -1.2752e-01,\n",
      "          -6.7356e-01,  5.2920e-01]]], device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -17.855553179979324\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0100,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5708,  0.3046, -0.7042,  ...,  0.6687, -0.6392,  0.2563]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -18.310145005583763\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5706,  0.3044, -0.7041,  ...,  0.6685, -0.6390,  0.2557]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92]\n",
      "Sum log prob -19.85464681359008\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3257, -0.0389,  0.2012,  ..., -0.3729,  0.3899, -0.1923]],\n",
      "\n",
      "        [[-0.6364,  0.0530, -0.7253,  ...,  0.1142, -0.6660,  0.5280]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -18.347801595926285\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5705,  0.3047, -0.7041,  ...,  0.6687, -0.6389,  0.2573]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -18.802929297089577\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5704,  0.3046, -0.7040,  ...,  0.6687, -0.6388,  0.2572]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92]\n",
      "Sum log prob -19.860701800789684\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3189, -0.0259,  0.2088,  ..., -0.3767,  0.3911, -0.1638]],\n",
      "\n",
      "        [[-0.6212,  0.0584, -0.7186,  ...,  0.0537, -0.6538,  0.5422]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -18.839300602674484\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5704,  0.3045, -0.7041,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -19.294454261660576\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5704,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.864907944574952\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3178, -0.0339,  0.2075,  ..., -0.3771,  0.3902, -0.1730]],\n",
      "\n",
      "        [[-0.6204,  0.0552, -0.7183,  ...,  0.0823, -0.6531,  0.5466]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -19.33106455206871\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5704,  0.3045, -0.7041,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -19.786279305815697\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -20.278042897582054\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -19.822815030813217\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.869489612989128\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3187, -0.0331,  0.2081,  ..., -0.3767,  0.3910, -0.1701]],\n",
      "\n",
      "        [[-0.6184,  0.0554, -0.7175,  ...,  0.0769, -0.6520,  0.5452]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -20.769828513264656\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -20.314591377973557\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.873939317651093\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0336,  0.2083,  ..., -0.3767,  0.3905, -0.1698]],\n",
      "\n",
      "        [[-0.6183,  0.0552, -0.7174,  ...,  0.0797, -0.6518,  0.5455]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -21.261612460017204\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -20.80637213587761\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.878426999319345\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3185, -0.0333,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6180,  0.0552, -0.7173,  ...,  0.0797, -0.6516,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -21.753397926688194\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -21.29815599322319\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.882896998431534\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6180,  0.0551, -0.7173,  ...,  0.0800, -0.6516,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -22.245183631777763\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -21.789941042661667\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.887371744494885\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -22.736969903111458\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -22.281726509332657\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.891844591591507\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -23.228755727410316\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -22.773512214422226\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.896317913662642\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -23.720541641116142\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -23.26529797911644\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.900790760759264\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -24.212327554821968\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -23.757083892822266\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.905263726599514\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -24.704113319516182\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -24.24887016415596\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.909736573696136\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/scratch/tb2817/1011_project/train_beamsearch.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(dataloaders[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]), leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39m# run beam search inference on the test set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m         beam_search_batch(data, seq2seq, vocab[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m], device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39m# create a matrix of the best attention score SRC token class \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39m# best_attn_labels = unk_postprocessing(data.source_vecs, attn_scores_mat)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39m# all_best_attn_labels.append(best_attn_labels)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m         \u001b[39m# all_cleaned_preds_list.append(cleaned_preds_list)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m         \u001b[39m# raw_labels_list.append(data.target_data)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/tb2817/1011_project/beamsearch.py:168\u001b[0m, in \u001b[0;36mbeam_search_batch\u001b[0;34m(batch, model, vocab, device, beam_width)\u001b[0m\n\u001b[1;32m    164\u001b[0m     encoder_state \u001b[39m=\u001b[39m (enc_output[i]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), enc_out_repr[:, i, :]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n\u001b[1;32m    165\u001b[0m     \u001b[39m# print(f'enc_output i {encoder_state[0].shape}') # [1, seq_len, hidden_dim*2]\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# print(f'enc_out_repr i {encoder_state[1].shape}') \u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     beam_search(model, encoder_state, vocab, device, beam_width)\n\u001b[1;32m    169\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/tb2817/1011_project/beamsearch.py:134\u001b[0m, in \u001b[0;36mbeam_search\u001b[0;34m(model, encoder_states, vocab, device, beam_width)\u001b[0m\n\u001b[1;32m    127\u001b[0m         dec_log_probs, dec_hidden, attn_scores_mat \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdec(\n\u001b[1;32m    128\u001b[0m             \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mdec_input, encoder_outs\u001b[39m=\u001b[39menc_output, hidden_init\u001b[39m=\u001b[39mdec_hidden\n\u001b[1;32m    129\u001b[0m         )\n\u001b[1;32m    131\u001b[0m         \u001b[39m# print(f'dec_log_probs {dec_log_probs.shape}') #[1,1,vocab_size]\u001b[39;00m\n\u001b[1;32m    132\u001b[0m         \u001b[39m# print(f'dec_hidden out {dec_hidden.shape}') # [2,1,600]\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m         beam\u001b[39m.\u001b[39;49madd_candidates(state, dec_log_probs\u001b[39m.\u001b[39;49msqueeze(\u001b[39m1\u001b[39;49m), dec_hidden)\n\u001b[1;32m    136\u001b[0m     beam\u001b[39m.\u001b[39mupdate_frontier()\n\u001b[1;32m    138\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcomplete paths \u001b[39m\u001b[39m{\u001b[39;00mbeam\u001b[39m.\u001b[39mget_complete_paths()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m )\n",
      "File \u001b[0;32m/scratch/tb2817/1011_project/beamsearch.py:63\u001b[0m, in \u001b[0;36mBeam.add_candidates\u001b[0;34m(self, prev_node, candidates_logprob, dec_hidden)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     58\u001b[0m word_logprob \u001b[39m=\u001b[39m candidates_logprob[\u001b[39m0\u001b[39m, i]\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     60\u001b[0m new_state \u001b[39m=\u001b[39m BeamNode(\n\u001b[1;32m     61\u001b[0m     log_prob\u001b[39m=\u001b[39mprev_node\u001b[39m.\u001b[39mlog_prob \u001b[39m+\u001b[39m word_logprob,\n\u001b[1;32m     62\u001b[0m     prefix\u001b[39m=\u001b[39mprev_node\u001b[39m.\u001b[39mprefix \u001b[39m+\u001b[39m [i],\n\u001b[0;32m---> 63\u001b[0m     dec_output\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mtensor([i])\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice),\n\u001b[1;32m     64\u001b[0m     dec_hidden\u001b[39m=\u001b[39mdec_hidden\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[39m# add state to candidate while mantaining heap variants\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcandidates) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeam_width:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run inference on the test set\n",
    "test_losses = []\n",
    "all_best_attn_labels = []\n",
    "all_preds_list = []\n",
    "all_labels_list = []\n",
    "raw_labels_list = []\n",
    "all_cleaned_preds_list = []\n",
    "all_bleu_1 = []\n",
    "all_bleu_2 = []\n",
    "all_bleu_3 = []\n",
    "all_bleu_4 = []\n",
    "all_meteor = []\n",
    "all_rouge_l = []\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(dataloaders['test']), leave=False):\n",
    "        # run beam search inference on the test set\n",
    "        beam_search_batch(data, seq2seq, vocab['target'], device, beam_width=1)\n",
    "        \n",
    "        # create a matrix of the best attention score SRC token class \n",
    "        # best_attn_labels = unk_postprocessing(data.source_vecs, attn_scores_mat)\n",
    "        # all_best_attn_labels.append(best_attn_labels)\n",
    "\n",
    "        # evaluate the predictions with the metrics\n",
    "        # bleu_1, bleu_2, bleu_3, bleu_4 = eval_metrics(preds_list, labels_list) # meteor, rouge_l\n",
    "        # all_bleu_1.append(bleu_1)\n",
    "        # all_bleu_2.append(bleu_2)\n",
    "        # all_bleu_3.append(bleu_3)\n",
    "        # all_bleu_4.append(bleu_4)\n",
    "        # all_meteor.append(meteor)\n",
    "        # all_rouge_l.append(rouge_l)\n",
    "\n",
    "        # replace all unk tokens with the SRC token with the highest attention\n",
    "        # cleaned_preds_list = []\n",
    "        # for sen_idx in range(len(preds_list)):\n",
    "        #     sentence = []\n",
    "        #     for tok_idx, token in enumerate(preds_list[sen_idx]):\n",
    "        #         if token == '<unk>':\n",
    "        #             src_id = int(best_attn_labels[sen_idx][tok_idx].item())\n",
    "        #             src_token = vocab['source'].decode_idx2token([src_id])\n",
    "        #             sentence.append(src_token[0])\n",
    "        #         else:\n",
    "        #             sentence.append(preds_list[sen_idx][tok_idx])\n",
    "        #     cleaned_preds_list.append(sentence)\n",
    "\n",
    "        # all_preds_list.append(preds_list)\n",
    "        # all_labels_list.append(labels_list)\n",
    "        # all_cleaned_preds_list.append(cleaned_preds_list)\n",
    "        # raw_labels_list.append(data.target_data)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target (Question) Label: what kind of classes are not offered in mittelschule ?\n",
      "Target (Question) Raw Prediction: what kind of classes are not offered in <unk> ?\n",
      "Target (Question) Postprocessed Prediction: what kind of classes are not offered in . ?\n",
      "\n",
      "Target (Question) Label: whats the first year that beyonce appear on the time 100 list ?\n",
      "Target (Question) Raw Prediction: whats the first year that <unk> appear on the time 100 list ?\n",
      "Target (Question) Postprocessed Prediction: whats the first year that . appear on the time 100 list ?\n",
      "\n",
      "Target (Question) Label: what are typical thermal mass material ?\n",
      "Target (Question) Raw Prediction: what are typical thermal mass material ?\n",
      "Target (Question) Postprocessed Prediction: what are typical thermal mass material ?\n",
      "\n",
      "Target (Question) Label: what is the annual precipitation ?\n",
      "Target (Question) Raw Prediction: what is the annual precipitation ?\n",
      "Target (Question) Postprocessed Prediction: what is the annual precipitation ?\n",
      "\n",
      "Target (Question) Label: luminous efficacy is measure in what unit ?\n",
      "Target (Question) Raw Prediction: luminous efficacy is measure in what unit ?\n",
      "Target (Question) Postprocessed Prediction: luminous efficacy is measure in what unit ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out a few postprocesse predictions\n",
    "for i in range(5):\n",
    "    print('Target (Question) Label:', \" \".join(raw_labels_list[0][i]))\n",
    "    print('Target (Question) Raw Prediction:', \" \".join(all_preds_list[0][i]))\n",
    "    print('Target (Question) Postprocessed Prediction:', \" \".join(all_cleaned_preds_list[0][i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAIN AND VAL LOSS\n",
    "import matplotlib.pyplot as plt \n",
    "def plot_over_training(per_epoch_metrics, title_name, num_epochs):\n",
    "    t = np.arange(1, num_epochs+1)\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    colors = ['tab:blue', 'tab:red']\n",
    "    ax1.set_xlabel('epochs')\n",
    "    ax1.set_ylabel('loss')\n",
    "\n",
    "    for key, color in zip(per_epoch_metrics, colors):\n",
    "        label = f'{key}_loss'\n",
    "        ax1.plot(t, per_epoch_metrics[key], color=color, linewidth=1, label=label)\n",
    "\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    fig.tight_layout\n",
    "    plt.title(title_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_over_training(plot_cache, 'Train and val loss over 15 epochs', 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d10e99a7d3ce7799ff53fffb01ded82fc9320fdeabd270dd8a29b265097acaf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
