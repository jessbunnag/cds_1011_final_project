{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/conda/1011_project/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from encoder import *\n",
    "from AttnDecoder import * \n",
    "from seq2seq import *\n",
    "\n",
    "from build_dataset import *\n",
    "from inference import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "from beamsearch import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set whether or not model is pretrained\n",
    "model_pretrained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "main_data_path = \"data/processed\"\n",
    "\n",
    "train_file_path = {\n",
    "    'source': f\"{main_data_path}/src-train.txt\",\n",
    "    'target': f\"{main_data_path}/tgt-train.txt\"\n",
    "}\n",
    "\n",
    "test_file_path = {\n",
    "    'source': f\"{main_data_path}/src-test.txt\",\n",
    "    'target': f\"{main_data_path}/tgt-test.txt\"\n",
    "}\n",
    "\n",
    "dev_file_path = {\n",
    "    'source': f\"{main_data_path}/src-dev.txt\",\n",
    "    'target': f\"{main_data_path}/tgt-dev.txt\"\n",
    "}\n",
    "\n",
    "# build vocab with train data only \n",
    "vocab = build_train_vocab(train_file_path)\n",
    "\n",
    "# build datasets for all train, test, dev\n",
    "datasets = {\n",
    "    'train': QAPair(train_file_path, vocab),\n",
    "    'test': QAPair(test_file_path, vocab),\n",
    "    'dev': QAPair(dev_file_path, vocab),\n",
    "}\n",
    "\n",
    "# build dataloaders\n",
    "batch_size = 32\n",
    "dataloaders = {}\n",
    "for split, dataset in datasets.items():\n",
    "    dataloaders[split] = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=partial(pad_collate_fn, pad_token=dataset.pad_idx)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load parsed GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "pretrained_vectors = {\n",
    "    'enc': torch.load(f'embeddings/encoder_emb_{embed_size}.pt').float(),\n",
    "    'dec': torch.load(f'embeddings/decoder_emb_{embed_size}.pt').float()\n",
    "}\n",
    "\n",
    "# input_size = len(train_dataset.answer_vocab) \n",
    "output_size = len(vocab['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Define train and eval steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch, model, optimizer, criterion, device):\n",
    "    input = batch.source_vecs.to(device) \n",
    "    inputs_len = batch.source_lens.to(device)\n",
    "    target = batch.target_vecs.to(device)\n",
    "    target_len = batch.target_lens.to(device) \n",
    "    target_input = target[:, :-1]\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    dec_log_probs, dec_hidden, attn_scores_mat = model(input, target_input, inputs_len, target_len)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    target_out = target[:, 1:]\n",
    "    loss = criterion(dec_log_probs.transpose(1, 2), target_out)\n",
    "    loss.backward()\n",
    "    # clip gradients\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0, norm_type=2)\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    # return the attention scores at the last time step\n",
    "    return loss.item(), dec_log_probs, attn_scores_mat\n",
    "\n",
    "def eval_step(batch, model, criterion, device):\n",
    "    input = batch.source_vecs.to(device) \n",
    "    inputs_len = batch.source_lens.to(device)\n",
    "    target = batch.target_vecs.to(device)\n",
    "    target_len = batch.target_lens.to(device) \n",
    "    target_input = target[:, :-1]\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    dec_log_probs, dec_hidden, attn_scores_mat = model(input, target_input, inputs_len, target_len)\n",
    "\n",
    "    target_out = target[:, 1:]\n",
    "    loss = criterion(dec_log_probs.transpose(1, 2), target_out)\n",
    "\n",
    "    # return the attention scores at the last time step\n",
    "    return loss.item(), dec_log_probs, attn_scores_mat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 1 = 5.525830451759273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [04:05<57:16, 245.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 1 = 4.826767617656339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 2 = 4.707652268169471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [08:09<53:03, 244.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 2 = 4.4452856676552885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 3 = 4.218288449552781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [12:13<48:53, 244.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 3 = 4.109762989705609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 4 = 3.814969809878917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [16:16<44:41, 243.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 4 = 3.935986372732347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 5 = 3.4987860474865706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [20:20<40:36, 243.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 5 = 3.7274187610995386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 6 = 3.2511984603923394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [24:22<36:29, 243.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 6 = 3.6530279722265018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 7 = 3.0496600653656603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [28:25<32:24, 243.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 7 = 3.5868226731977155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 8 = 2.8747176341560285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [32:28<28:22, 243.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 8 = 3.520006387464462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 9 = 2.56800848648757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [36:32<24:20, 243.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 9 = 3.4353575994891505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 10 = 2.4512601167680566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [40:37<20:19, 243.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 10 = 3.441953785957829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 11 = 2.3574249971145615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [44:41<16:15, 243.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 11 = 3.4511766286306482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 12 = 2.272238029061368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [48:45<12:11, 243.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 12 = 3.4471841646778967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 13 = 2.1938394123026312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [52:49<08:07, 243.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 13 = 3.4890000781705304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 14 = 2.1167864117144024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [56:52<04:03, 243.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 14 = 3.489010271846607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss after epoch 15 = 2.044265194800676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [1:00:55<00:00, 243.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after epoch 15 = 3.5287296887367003\n"
     ]
    }
   ],
   "source": [
    "# TRAIN LOOP \n",
    "\n",
    "if not model_pretrained:\n",
    "    # initial learning rate\n",
    "    lr = 1.0\n",
    "    # initialize the model, optimizer, and criterion\n",
    "    seq2seq = Seq2Seq(pretrained_vectors, hidden_size=600, output_size=output_size)\n",
    "    optimizer = torch.optim.SGD(seq2seq.parameters(), lr=lr)\n",
    "    criterion = nn.NLLLoss(ignore_index=datasets['train'].pad_idx)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    seq2seq.to(device)\n",
    "\n",
    "    plot_cache = {}\n",
    "    plot_cache['train'] = []\n",
    "    plot_cache['test'] = []\n",
    "\n",
    "    # halve lr at epoch 8\n",
    "    scheduler = StepLR(optimizer, step_size=8, gamma=0.5) \n",
    "\n",
    "    NUM_EPOCHS = 15\n",
    "    for epoch in tqdm(range(NUM_EPOCHS)):    \n",
    "        # train \n",
    "        train_losses = []\n",
    "        for i, data in tqdm(enumerate(dataloaders['train']), leave=False):\n",
    "            curr_loss, dec_log_probs, attn_scores_mat = train_step(data, seq2seq, optimizer, criterion, device)\n",
    "\n",
    "            train_losses.append(curr_loss)\n",
    "\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        print(f'Train loss after epoch {epoch+1} = {avg_train_loss}')\n",
    "\n",
    "        # eval \n",
    "        test_losses = []\n",
    "        with torch.no_grad():\n",
    "            for i, data in tqdm(enumerate(dataloaders['test']), leave=False):\n",
    "                curr_loss, dec_log_probs, attn_scores_mat = eval_step(data, seq2seq, criterion, device)\n",
    "\n",
    "                test_losses.append(curr_loss)\n",
    "\n",
    "            avg_test_loss = np.mean(test_losses)\n",
    "            print(f'Test loss after epoch {epoch+1} = {avg_test_loss}')\n",
    "\n",
    "        plot_cache['train'].append(avg_train_loss)\n",
    "        plot_cache['test'].append(avg_test_loss)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # save the model state\n",
    "    torch.save({'state_dict': seq2seq.state_dict(), 'plot_cache': plot_cache}, 'trained_seq2seq_statedict.pt')\n",
    "else:\n",
    "    # reload the model\n",
    "    seq2seq = Seq2Seq(pretrained_vectors, hidden_size=600, output_size=output_size)\n",
    "    criterion = nn.NLLLoss(ignore_index=datasets['train'].pad_idx)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seq2seq.to(device)\n",
    "\n",
    "    checkpoint = torch.load('trained_seq2seq_statedict.pt')\n",
    "    seq2seq.load_state_dict(checkpoint['state_dict'])\n",
    "    plot_cache = checkpoint['plot_cache']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target question: ['how', 'many', 'people', 'were', 'left', 'homeless', 'because', 'of', 'the', 'earthquake', '?']\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134]\n",
      "Sum log prob -14.964481353759766\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[ 0.0332, -0.2879, -0.0891,  ...,  0.1773, -0.3392, -0.0314]],\n",
      "\n",
      "        [[-0.6489,  0.1066, -0.7120,  ...,  0.6436, -0.6028,  0.4995]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers']\n",
      "Prefix [1, 6207]\n",
      "Sum log prob -14.166219711303711\n",
      "Decoder output tensor([[6207]], device='cuda:0')\n",
      "Decoder hidden tensor([[[ 0.0332, -0.2879, -0.0891,  ...,  0.1773, -0.3392, -0.0314]],\n",
      "\n",
      "        [[-0.6489,  0.1066, -0.7120,  ...,  0.6436, -0.6028,  0.4995]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs']\n",
      "Prefix [1, 6215]\n",
      "Sum log prob -13.877104759216309\n",
      "Decoder output tensor([[6215]], device='cuda:0')\n",
      "Decoder hidden tensor([[[ 0.0332, -0.2879, -0.0891,  ...,  0.1773, -0.3392, -0.0314]],\n",
      "\n",
      "        [[-0.6489,  0.1066, -0.7120,  ...,  0.6436, -0.6028,  0.4995]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'appalachians']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134]\n",
      "Sum log prob -15.985390543937683\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0934, -0.2998,  0.1657,  ...,  0.1530, -0.2206, -0.1528]],\n",
      "\n",
      "        [[-0.5903,  0.2568, -0.7184,  ...,  0.7153, -0.6323,  0.1270]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers']\n",
      "Prefix [1, 2134, 2134]\n",
      "Sum log prob -15.620332479476929\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[ 0.0031, -0.2448,  0.0719,  ...,  0.0367, -0.3223, -0.4299]],\n",
      "\n",
      "        [[-0.5908,  0.3845, -0.7246,  ...,  0.7015, -0.6494,  0.0772]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2573]\n",
      "Sum log prob -15.732989192008972\n",
      "Decoder output tensor([[2573]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0934, -0.2998,  0.1657,  ...,  0.1530, -0.2206, -0.1528]],\n",
      "\n",
      "        [[-0.5903,  0.2568, -0.7184,  ...,  0.7153, -0.6323,  0.1270]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'kilometers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134]\n",
      "Sum log prob -16.183019176125526\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0361, -0.2282,  0.0067,  ...,  0.0558, -0.2395, -0.3203]],\n",
      "\n",
      "        [[-0.5760,  0.2629, -0.7159,  ...,  0.6713, -0.6155,  0.1896]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134]\n",
      "Sum log prob -15.788331121206284\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0355, -0.2385,  0.0347,  ...,  0.0751, -0.2307, -0.3239]],\n",
      "\n",
      "        [[-0.5927,  0.2832, -0.7119,  ...,  0.6779, -0.6413,  0.2495]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2573, 2573]\n",
      "Sum log prob -16.02015322446823\n",
      "Decoder output tensor([[2573]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0723, -0.2237,  0.1860,  ...,  0.0194,  0.0304, -0.4114]],\n",
      "\n",
      "        [[-0.5798,  0.1333, -0.7148,  ...,  0.7308, -0.6180, -0.5674]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'kilometers', 'kilometers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2573, 2573, 2573]\n",
      "Sum log prob -17.761501371860504\n",
      "Decoder output tensor([[2573]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0796, -0.2241,  0.1222,  ..., -0.0199,  0.0612, -0.3980]],\n",
      "\n",
      "        [[-0.5352,  0.0925, -0.6779,  ...,  0.7023, -0.5293, -0.4615]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'kilometers', 'kilometers', 'kilometers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -16.411918371915817\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0266, -0.2386,  0.0049,  ...,  0.0312, -0.2150, -0.3418]],\n",
      "\n",
      "        [[-0.5644,  0.3207, -0.7042,  ...,  0.6729, -0.6342,  0.2768]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134]\n",
      "Sum log prob -16.85870762169361\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0289, -0.2393,  0.0097,  ...,  0.0290, -0.2120, -0.3389]],\n",
      "\n",
      "        [[-0.5628,  0.3183, -0.7000,  ...,  0.6746, -0.6346,  0.2679]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213]\n",
      "Sum log prob -19.316006153821945\n",
      "Decoder output tensor([[2213]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0285, -0.2403,  0.0105,  ...,  0.0325, -0.2128, -0.3417]],\n",
      "\n",
      "        [[-0.5738,  0.3044, -0.7050,  ...,  0.6694, -0.6416,  0.2579]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -16.864006489515305\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0285, -0.2403,  0.0105,  ...,  0.0325, -0.2128, -0.3417]],\n",
      "\n",
      "        [[-0.5738,  0.3044, -0.7050,  ...,  0.6694, -0.6416,  0.2579]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -17.31217809021473\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0288, -0.2400,  0.0093,  ...,  0.0318, -0.2120, -0.3418]],\n",
      "\n",
      "        [[-0.5724,  0.3009, -0.7046,  ...,  0.6677, -0.6402,  0.2640]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92]\n",
      "Sum log prob -19.32288312120363\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.1588, -0.2280,  0.0933,  ..., -0.1320,  0.1261, -0.2329]],\n",
      "\n",
      "        [[-0.6109,  0.2040, -0.7081,  ...,  0.3533, -0.6562,  0.6308]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -17.36667338013649\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0275, -0.2404,  0.0105,  ...,  0.0320, -0.2122, -0.3418]],\n",
      "\n",
      "        [[-0.5706,  0.3054, -0.7043,  ...,  0.6688, -0.6389,  0.2601]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -17.821326091885567\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0274, -0.2404,  0.0104,  ...,  0.0317, -0.2120, -0.3419]],\n",
      "\n",
      "        [[-0.5700,  0.3049, -0.7039,  ...,  0.6689, -0.6385,  0.2583]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92]\n",
      "Sum log prob -19.85207175416872\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-2.9836e-01,  5.0303e-04,  1.4563e-01,  ..., -3.8836e-01,\n",
      "           4.2521e-01, -1.1523e-01]],\n",
      "\n",
      "        [[-6.1646e-01,  1.1872e-01, -7.1922e-01,  ..., -1.2752e-01,\n",
      "          -6.7356e-01,  5.2920e-01]]], device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -17.855553179979324\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0100,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5708,  0.3046, -0.7042,  ...,  0.6687, -0.6392,  0.2563]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -18.310145005583763\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5706,  0.3044, -0.7041,  ...,  0.6685, -0.6390,  0.2557]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92]\n",
      "Sum log prob -19.85464681359008\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3257, -0.0389,  0.2012,  ..., -0.3729,  0.3899, -0.1923]],\n",
      "\n",
      "        [[-0.6364,  0.0530, -0.7253,  ...,  0.1142, -0.6660,  0.5280]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -18.347801595926285\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5705,  0.3047, -0.7041,  ...,  0.6687, -0.6389,  0.2573]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -18.802929297089577\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5704,  0.3046, -0.7040,  ...,  0.6687, -0.6388,  0.2572]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92]\n",
      "Sum log prob -19.860701800789684\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3189, -0.0259,  0.2088,  ..., -0.3767,  0.3911, -0.1638]],\n",
      "\n",
      "        [[-0.6212,  0.0584, -0.7186,  ...,  0.0537, -0.6538,  0.5422]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -18.839300602674484\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5704,  0.3045, -0.7041,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -19.294454261660576\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5704,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.864907944574952\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3178, -0.0339,  0.2075,  ..., -0.3771,  0.3902, -0.1730]],\n",
      "\n",
      "        [[-0.6204,  0.0552, -0.7183,  ...,  0.0823, -0.6531,  0.5466]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -19.33106455206871\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5704,  0.3045, -0.7041,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -19.786279305815697\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -20.278042897582054\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -19.822815030813217\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.869489612989128\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3187, -0.0331,  0.2081,  ..., -0.3767,  0.3910, -0.1701]],\n",
      "\n",
      "        [[-0.6184,  0.0554, -0.7175,  ...,  0.0769, -0.6520,  0.5452]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -20.769828513264656\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -20.314591377973557\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.873939317651093\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0336,  0.2083,  ..., -0.3767,  0.3905, -0.1698]],\n",
      "\n",
      "        [[-0.6183,  0.0552, -0.7174,  ...,  0.0797, -0.6518,  0.5455]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -21.261612460017204\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -20.80637213587761\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.878426999319345\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3185, -0.0333,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6180,  0.0552, -0.7173,  ...,  0.0797, -0.6516,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -21.753397926688194\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -21.29815599322319\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.882896998431534\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6180,  0.0551, -0.7173,  ...,  0.0800, -0.6516,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -22.245183631777763\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -21.789941042661667\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.887371744494885\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -22.736969903111458\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -22.281726509332657\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.891844591591507\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -23.228755727410316\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -22.773512214422226\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.896317913662642\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -23.720541641116142\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -23.26529797911644\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.900790760759264\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -24.212327554821968\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -23.757083892822266\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.905263726599514\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "len candidates 3\n",
      "after updating frontier\n",
      "Prefix [1, 6207, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -24.704113319516182\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'reefs', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134, 2134]\n",
      "Sum log prob -24.24887016415596\n",
      "Decoder output tensor([[2134]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.0277, -0.2404,  0.0101,  ...,  0.0321, -0.2123, -0.3420]],\n",
      "\n",
      "        [[-0.5703,  0.3045, -0.7040,  ...,  0.6687, -0.6388,  0.2571]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'glaciers']\n",
      "Prefix [1, 2134, 2134, 2134, 2134, 2213, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92]\n",
      "Sum log prob -19.909736573696136\n",
      "Decoder output tensor([[92]], device='cuda:0')\n",
      "Decoder hidden tensor([[[-0.3186, -0.0334,  0.2082,  ..., -0.3767,  0.3906, -0.1699]],\n",
      "\n",
      "        [[-0.6179,  0.0551, -0.7173,  ...,  0.0800, -0.6515,  0.5454]]],\n",
      "       device='cuda:0')\n",
      "prefix ['<bos>', 'glaciers', 'glaciers', 'glaciers', 'glaciers', 'tourists', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along', 'along']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/scratch/tb2817/1011_project/train_beamsearch.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(dataloaders[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m]), leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39m# run beam search inference on the test set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m         beam_search_batch(data, seq2seq, vocab[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m], device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39m# create a matrix of the best attention score SRC token class \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39m# best_attn_labels = unk_postprocessing(data.source_vecs, attn_scores_mat)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39m# all_best_attn_labels.append(best_attn_labels)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m         \u001b[39m# all_cleaned_preds_list.append(cleaned_preds_list)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m         \u001b[39m# raw_labels_list.append(data.target_data)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/tb2817/1011_project/beamsearch.py:168\u001b[0m, in \u001b[0;36mbeam_search_batch\u001b[0;34m(batch, model, vocab, device, beam_width)\u001b[0m\n\u001b[1;32m    164\u001b[0m     encoder_state \u001b[39m=\u001b[39m (enc_output[i]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m), enc_out_repr[:, i, :]\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n\u001b[1;32m    165\u001b[0m     \u001b[39m# print(f'enc_output i {encoder_state[0].shape}') # [1, seq_len, hidden_dim*2]\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# print(f'enc_out_repr i {encoder_state[1].shape}') \u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m     beam_search(model, encoder_state, vocab, device, beam_width)\n\u001b[1;32m    169\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/tb2817/1011_project/beamsearch.py:134\u001b[0m, in \u001b[0;36mbeam_search\u001b[0;34m(model, encoder_states, vocab, device, beam_width)\u001b[0m\n\u001b[1;32m    127\u001b[0m         dec_log_probs, dec_hidden, attn_scores_mat \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdec(\n\u001b[1;32m    128\u001b[0m             \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mdec_input, encoder_outs\u001b[39m=\u001b[39menc_output, hidden_init\u001b[39m=\u001b[39mdec_hidden\n\u001b[1;32m    129\u001b[0m         )\n\u001b[1;32m    131\u001b[0m         \u001b[39m# print(f'dec_log_probs {dec_log_probs.shape}') #[1,1,vocab_size]\u001b[39;00m\n\u001b[1;32m    132\u001b[0m         \u001b[39m# print(f'dec_hidden out {dec_hidden.shape}') # [2,1,600]\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m         beam\u001b[39m.\u001b[39;49madd_candidates(state, dec_log_probs\u001b[39m.\u001b[39;49msqueeze(\u001b[39m1\u001b[39;49m), dec_hidden)\n\u001b[1;32m    136\u001b[0m     beam\u001b[39m.\u001b[39mupdate_frontier()\n\u001b[1;32m    138\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcomplete paths \u001b[39m\u001b[39m{\u001b[39;00mbeam\u001b[39m.\u001b[39mget_complete_paths()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m )\n",
      "File \u001b[0;32m/scratch/tb2817/1011_project/beamsearch.py:63\u001b[0m, in \u001b[0;36mBeam.add_candidates\u001b[0;34m(self, prev_node, candidates_logprob, dec_hidden)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     58\u001b[0m word_logprob \u001b[39m=\u001b[39m candidates_logprob[\u001b[39m0\u001b[39m, i]\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     60\u001b[0m new_state \u001b[39m=\u001b[39m BeamNode(\n\u001b[1;32m     61\u001b[0m     log_prob\u001b[39m=\u001b[39mprev_node\u001b[39m.\u001b[39mlog_prob \u001b[39m+\u001b[39m word_logprob,\n\u001b[1;32m     62\u001b[0m     prefix\u001b[39m=\u001b[39mprev_node\u001b[39m.\u001b[39mprefix \u001b[39m+\u001b[39m [i],\n\u001b[0;32m---> 63\u001b[0m     dec_output\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mtensor([i])\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice),\n\u001b[1;32m     64\u001b[0m     dec_hidden\u001b[39m=\u001b[39mdec_hidden\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[39m# add state to candidate while mantaining heap variants\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcandidates) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbeam_width:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run inference on the test set\n",
    "test_losses = []\n",
    "all_best_attn_labels = []\n",
    "all_preds_list = []\n",
    "all_labels_list = []\n",
    "raw_labels_list = []\n",
    "all_cleaned_preds_list = []\n",
    "all_bleu_1 = []\n",
    "all_bleu_2 = []\n",
    "all_bleu_3 = []\n",
    "all_bleu_4 = []\n",
    "all_meteor = []\n",
    "all_rouge_l = []\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(dataloaders['test']), leave=False):\n",
    "        # run beam search inference on the test set\n",
    "        beam_search_batch(data, seq2seq, vocab['target'], device, beam_width=1)\n",
    "\n",
    "        preds_list = []\n",
    "        labels_list = []\n",
    "        for j in range(len(data.source_vecs)):\n",
    "            pred = generate_with_beam(seq2seq, data.source_data[j], vocab, beam_width=3)\n",
    "            preds_list.append(pred)\n",
    "            labels_list.append(data.target_data[i])\n",
    "        \n",
    "        # create a matrix of the best attention score SRC token class \n",
    "        # best_attn_labels = unk_postprocessing(data.source_vecs, attn_scores_mat)\n",
    "        # all_best_attn_labels.append(best_attn_labels)\n",
    "\n",
    "        # evaluate the predictions with the metrics\n",
    "        # bleu_1, bleu_2, bleu_3, bleu_4 = eval_metrics(preds_list, labels_list) # meteor, rouge_l\n",
    "        # all_bleu_1.append(bleu_1)\n",
    "        # all_bleu_2.append(bleu_2)\n",
    "        # all_bleu_3.append(bleu_3)\n",
    "        # all_bleu_4.append(bleu_4)\n",
    "        # all_meteor.append(meteor)\n",
    "        # all_rouge_l.append(rouge_l)\n",
    "\n",
    "        # replace all unk tokens with the SRC token with the highest attention\n",
    "        # cleaned_preds_list = []\n",
    "        # for sen_idx in range(len(preds_list)):\n",
    "        #     sentence = []\n",
    "        #     for tok_idx, token in enumerate(preds_list[sen_idx]):\n",
    "        #         if token == '<unk>':\n",
    "        #             src_id = int(best_attn_labels[sen_idx][tok_idx].item())\n",
    "        #             src_token = vocab['source'].decode_idx2token([src_id])\n",
    "        #             sentence.append(src_token[0])\n",
    "        #         else:\n",
    "        #             sentence.append(preds_list[sen_idx][tok_idx])\n",
    "        #     cleaned_preds_list.append(sentence)\n",
    "\n",
    "        # all_preds_list.append(preds_list)\n",
    "        # all_labels_list.append(labels_list)\n",
    "        # all_cleaned_preds_list.append(cleaned_preds_list)\n",
    "        # raw_labels_list.append(data.target_data)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target (Question) Label: what kind of classes are not offered in mittelschule ?\n",
      "Target (Question) Raw Prediction: what kind of classes are not offered in <unk> ?\n",
      "Target (Question) Postprocessed Prediction: what kind of classes are not offered in . ?\n",
      "\n",
      "Target (Question) Label: whats the first year that beyonce appear on the time 100 list ?\n",
      "Target (Question) Raw Prediction: whats the first year that <unk> appear on the time 100 list ?\n",
      "Target (Question) Postprocessed Prediction: whats the first year that . appear on the time 100 list ?\n",
      "\n",
      "Target (Question) Label: what are typical thermal mass material ?\n",
      "Target (Question) Raw Prediction: what are typical thermal mass material ?\n",
      "Target (Question) Postprocessed Prediction: what are typical thermal mass material ?\n",
      "\n",
      "Target (Question) Label: what is the annual precipitation ?\n",
      "Target (Question) Raw Prediction: what is the annual precipitation ?\n",
      "Target (Question) Postprocessed Prediction: what is the annual precipitation ?\n",
      "\n",
      "Target (Question) Label: luminous efficacy is measure in what unit ?\n",
      "Target (Question) Raw Prediction: luminous efficacy is measure in what unit ?\n",
      "Target (Question) Postprocessed Prediction: luminous efficacy is measure in what unit ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out a few postprocesse predictions\n",
    "for i in range(5):\n",
    "    print('Target (Question) Label:', \" \".join(raw_labels_list[0][i]))\n",
    "    print('Target (Question) Raw Prediction:', \" \".join(all_preds_list[0][i]))\n",
    "    print('Target (Question) Postprocessed Prediction:', \" \".join(all_cleaned_preds_list[0][i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAIN AND VAL LOSS\n",
    "import matplotlib.pyplot as plt \n",
    "def plot_over_training(per_epoch_metrics, title_name, num_epochs):\n",
    "    t = np.arange(1, num_epochs+1)\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    colors = ['tab:blue', 'tab:red']\n",
    "    ax1.set_xlabel('epochs')\n",
    "    ax1.set_ylabel('loss')\n",
    "\n",
    "    for key, color in zip(per_epoch_metrics, colors):\n",
    "        label = f'{key}_loss' if key != 'test' else 'val_loss'\n",
    "        ax1.plot(t, per_epoch_metrics[key], color=color, linewidth=1, label=label)\n",
    "\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    fig.tight_layout\n",
    "    plt.title(title_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/scratch/tb2817/1011_project/train_beamsearch.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m plot_over_training(plot_cache, \u001b[39m'\u001b[39;49m\u001b[39mTrain and val loss over 15 epochs\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m15\u001b[39;49m)\n",
      "\u001b[1;32m/scratch/tb2817/1011_project/train_beamsearch.ipynb Cell 15\u001b[0m in \u001b[0;36mplot_over_training\u001b[0;34m(per_epoch_metrics, title_name, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m_loss\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     ax1\u001b[39m.\u001b[39mplot(t, per_epoch_metrics[key], color\u001b[39m=\u001b[39mcolor, linewidth\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, label\u001b[39m=\u001b[39mlabel)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m ax1\u001b[39m.\u001b[39mtick_params(axis\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_beamsearch.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m ax1\u001b[39m.\u001b[39mlegend(loc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mupper right\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_over_training(plot_cache, 'Train and val loss over 15 epochs', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d10e99a7d3ce7799ff53fffb01ded82fc9320fdeabd270dd8a29b265097acaf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
