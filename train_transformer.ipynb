{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/tb2817/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/tb2817/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from encoder import *\n",
    "from AttnDecoder import * \n",
    "from seq2seq_transformer import *\n",
    "\n",
    "from build_dataset import *\n",
    "from inference import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "from greedy_search import generate_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set whether or not model is pretrained\n",
    "model_pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "main_data_path = \"data/processed\"\n",
    "\n",
    "train_file_path = {\n",
    "    'source': f\"{main_data_path}/src-train.txt\",\n",
    "    'target': f\"{main_data_path}/tgt-train.txt\"\n",
    "}\n",
    "\n",
    "test_file_path = {\n",
    "    'source': f\"{main_data_path}/src-test.txt\",\n",
    "    'target': f\"{main_data_path}/tgt-test.txt\"\n",
    "}\n",
    "\n",
    "dev_file_path = {\n",
    "    'source': f\"{main_data_path}/src-dev.txt\",\n",
    "    'target': f\"{main_data_path}/tgt-dev.txt\"\n",
    "}\n",
    "\n",
    "# build vocab with train data only \n",
    "vocab = build_train_vocab(train_file_path)\n",
    "\n",
    "# build datasets for all train, test, dev\n",
    "datasets = {\n",
    "    'train': QAPair(train_file_path, vocab),\n",
    "    'test': QAPair(test_file_path, vocab),\n",
    "    'dev': QAPair(dev_file_path, vocab),\n",
    "}\n",
    "\n",
    "# build dataloaders\n",
    "batch_size = 64\n",
    "dataloaders = {}\n",
    "for split, dataset in datasets.items():\n",
    "    dataloaders[split] = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=partial(pad_collate_fn, pad_token=dataset.pad_idx)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load parsed GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "pretrained_vectors = {\n",
    "    'enc': torch.load(f'embeddings/encoder_emb_{embed_size}.pt').float(),\n",
    "    'dec': torch.load(f'embeddings/decoder_emb_{embed_size}.pt').float()\n",
    "}\n",
    "\n",
    "# input_size = len(train_dataset.answer_vocab) \n",
    "output_size = len(vocab['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Define train and eval steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch, model, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    source = batch.source_vecs.to(device) \n",
    "    source_len = batch.source_lens.to(device)\n",
    "    target = batch.target_vecs.to(device)\n",
    "    target_len = batch.target_lens.to(device) \n",
    "\n",
    "    target_input = target[:, :-1]\n",
    "\n",
    "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(source, target_input)\n",
    "\n",
    "    logits = model(source, target_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    target_out = target[:, 1:]\n",
    "    # print(f'dec_log_probs {dec_log_probs.shape}')\n",
    "    # print(f'target_out {target_out.shape}')\n",
    "    loss = criterion(logits.transpose(1, 2), target_out)\n",
    "    loss.backward()\n",
    "    # clip gradients\n",
    "    # nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0, norm_type=2)\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    # return the attention scores at the last time step\n",
    "    return loss.item(), logits\n",
    "\n",
    "def eval_step(batch, model, criterion, device):\n",
    "    model.eval()\n",
    "    source = batch.source_vecs.to(device) \n",
    "    inputs_len = batch.source_lens.to(device)\n",
    "    target = batch.target_vecs.to(device)\n",
    "    target_len = batch.target_lens.to(device) \n",
    "\n",
    "    target_input = target[:, :-1]\n",
    "\n",
    "    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(source, target_input)\n",
    "\n",
    "    logits = model(source, target_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "    \n",
    "    target_out = target[:, 1:]\n",
    "\n",
    "    # scores = s2s_output.view(-1, s2s_output.size(-1))\n",
    "    \n",
    "    loss = criterion(logits.transpose(1, 2), target_out)\n",
    "\n",
    "    # return the attention scores at the last time step\n",
    "    return loss.item(), logits\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Run train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN LOOP \n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 2\n",
    "EMBED_SIZE = 300\n",
    "NHEAD = 10\n",
    "\n",
    "if not model_pretrained:\n",
    "    # initial learning rate\n",
    "    lr = 0.01\n",
    "    # initialize the model, optimizer, and criterion\n",
    "    seq2seq = Seq2SeqTransformer(\n",
    "        NUM_ENCODER_LAYERS,\n",
    "        NUM_DECODER_LAYERS,\n",
    "        EMBED_SIZE,\n",
    "        NHEAD,\n",
    "        pretrained_vectors, \n",
    "        tgt_vocab_size=len(vocab['target'])\n",
    "    )\n",
    "    optimizer = torch.optim.SGD(seq2seq.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=datasets['train'].pad_idx)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    seq2seq.to(device)\n",
    "\n",
    "    plot_cache = {}\n",
    "    plot_cache['train'] = []\n",
    "    plot_cache['dev'] = []\n",
    "\n",
    "    # halve lr at epoch 8\n",
    "    scheduler = StepLR(optimizer, step_size=20, gamma=0.5) \n",
    "\n",
    "    NUM_EPOCHS = 15\n",
    "    for epoch in tqdm(range(NUM_EPOCHS)):    \n",
    "        # train \n",
    "        train_losses = []\n",
    "        for i, data in tqdm(enumerate(dataloaders['train']), leave=False):\n",
    "            curr_loss, dec_log_probs = train_step(data, seq2seq, optimizer, criterion, device)\n",
    "\n",
    "            train_losses.append(curr_loss)\n",
    "\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        print(f'Train loss after epoch {epoch+1} = {avg_train_loss}')\n",
    "\n",
    "        # eval \n",
    "        test_losses = []\n",
    "        with torch.no_grad():\n",
    "            for i, data in tqdm(enumerate(dataloaders['dev']), leave=False):\n",
    "                curr_loss, dec_log_probs = eval_step(data, seq2seq, criterion, device)\n",
    "\n",
    "                test_losses.append(curr_loss)\n",
    "\n",
    "            avg_test_loss = np.mean(test_losses)\n",
    "            print(f'Dev loss after epoch {epoch+1} = {avg_test_loss}')\n",
    "\n",
    "        plot_cache['train'].append(avg_train_loss)\n",
    "        plot_cache['dev'].append(avg_test_loss)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # save the model state\n",
    "    torch.save({'state_dict': seq2seq.state_dict(), 'plot_cache': plot_cache}, 'trained_transformer_statedict.pt')\n",
    "else:\n",
    "    # reload the model\n",
    "    seq2seq = Seq2SeqTransformer(\n",
    "        NUM_ENCODER_LAYERS,\n",
    "        NUM_DECODER_LAYERS,\n",
    "        EMBED_SIZE,\n",
    "        NHEAD,\n",
    "        pretrained_vectors, \n",
    "        tgt_vocab_size=len(vocab['target'])\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=datasets['train'].pad_idx)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    seq2seq.to(device)\n",
    "\n",
    "    checkpoint = torch.load('trained_transformer_statedict.pt')\n",
    "    seq2seq.load_state_dict(checkpoint['state_dict'])\n",
    "    plot_cache = checkpoint['plot_cache']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss = 5.182699982837964\n",
      "Average BLEU_1 Score = 0.22971156713726096\n",
      "Average BLEU_2 Score = 0.05311787730559459\n",
      "Average BLEU_3 Score = 0.010310847228258308\n",
      "Average BLEU_4 Score = 0.0054559309413576475\n",
      "Average METEOR Score = 0.12901500029560548\n",
      "Average ROUGE_L Score = 0.17825822532176971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# run inference on the test set\n",
    "test_losses = []\n",
    "all_best_attn_labels = []\n",
    "all_preds_list = []\n",
    "all_labels_list = []\n",
    "raw_labels_list = []\n",
    "raw_source_list = []\n",
    "all_cleaned_preds_list = []\n",
    "all_bleu_1 = []\n",
    "all_bleu_2 = []\n",
    "all_bleu_3 = []\n",
    "all_bleu_4 = []\n",
    "all_meteor = []\n",
    "all_rouge_l = []\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(dataloaders['test']), leave=False):\n",
    "        # run evaluation on the test set\n",
    "        curr_loss, dec_log_probs = eval_step(data, seq2seq, criterion, device)\n",
    "        test_losses.append(curr_loss)\n",
    "\n",
    "        # run vanilla inference on the test set\n",
    "        preds_list, labels_list = vanilla_inference(dec_log_probs, data.target_vecs, vocab['target'])\n",
    "\n",
    "        # evaluate the predictions with the metrics\n",
    "        bleu_1, bleu_2, bleu_3, bleu_4, meteor, rouge_l = eval_metrics(preds_list, labels_list) # meteor, rouge_l\n",
    "        all_bleu_1.append(bleu_1)\n",
    "        all_bleu_2.append(bleu_2)\n",
    "        all_bleu_3.append(bleu_3)\n",
    "        all_bleu_4.append(bleu_4)\n",
    "        all_meteor.append(meteor)\n",
    "        all_rouge_l.append(rouge_l)\n",
    "\n",
    "        all_preds_list.append(preds_list)\n",
    "        all_labels_list.append(labels_list)\n",
    "        # all_cleaned_preds_list.append(cleaned_preds_list)\n",
    "        raw_labels_list.append(data.target_data)\n",
    "        raw_source_list.append(data.source_data)\n",
    "\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    avg_bleu_1 = np.mean(all_bleu_1)\n",
    "    avg_bleu_2 = np.mean(all_bleu_2)\n",
    "    avg_bleu_3 = np.mean(all_bleu_3)\n",
    "    avg_bleu_4 = np.mean(all_bleu_4)\n",
    "    avg_meteor = np.mean(all_meteor)\n",
    "    avg_rouge_l = np.mean(all_rouge_l)\n",
    "\n",
    "    print(f'Average Test Loss = {avg_test_loss}')\n",
    "    print(f'Average BLEU_1 Score = {avg_bleu_1}')\n",
    "    print(f'Average BLEU_2 Score = {avg_bleu_2}')\n",
    "    print(f'Average BLEU_3 Score = {avg_bleu_3}')\n",
    "    print(f'Average BLEU_4 Score = {avg_bleu_4}')\n",
    "    print(f'Average METEOR Score = {avg_meteor}')\n",
    "    print(f'Average ROUGE_L Score = {avg_rouge_l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src torch.Size([26])\n",
      "src_mask torch.Size([26, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ys torch.Size([1, 1])\n",
      "memory torch.Size([26, 26, 300])\n",
      "tgt_mask torch.Size([1, 1])\n",
      "embedding torch.Size([1, 1, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[26, 10, 30]' is invalid for input of size 202800",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/scratch/tb2817/1011_project/train_transformer.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_transformer.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m labels_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_transformer.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(data\u001b[39m.\u001b[39msource_vecs)):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_transformer.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     pred \u001b[39m=\u001b[39m generate_question(seq2seq, data\u001b[39m.\u001b[39;49msource_data[j], vocab)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_transformer.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     preds_list\u001b[39m.\u001b[39mappend(pred)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgreenecomputecontainer/scratch/tb2817/1011_project/train_transformer.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     labels_list\u001b[39m.\u001b[39mappend(data\u001b[39m.\u001b[39mtarget_data[i])\n",
      "File \u001b[0;32m/scratch/tb2817/1011_project/greedy_search.py:44\u001b[0m, in \u001b[0;36mgenerate_question\u001b[0;34m(model, src_sentence, vocab)\u001b[0m\n\u001b[1;32m     42\u001b[0m num_tokens \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     43\u001b[0m src_mask \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mzeros(num_tokens, num_tokens))\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mbool)\n\u001b[0;32m---> 44\u001b[0m tgt_tokens \u001b[39m=\u001b[39m greedy_decode(\n\u001b[1;32m     45\u001b[0m     model,  src, src_mask, max_len\u001b[39m=\u001b[39;49mnum_tokens \u001b[39m+\u001b[39;49m \u001b[39m5\u001b[39;49m, start_symbol\u001b[39m=\u001b[39;49mBOS_IDX)\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     46\u001b[0m \u001b[39mreturn\u001b[39;00m vocab[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdecode_idx2token(tgt_tokens\u001b[39m.\u001b[39mtolist())\n",
      "File \u001b[0;32m/scratch/tb2817/1011_project/greedy_search.py:25\u001b[0m, in \u001b[0;36mgreedy_decode\u001b[0;34m(model, src, src_mask, max_len, start_symbol)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmemory \u001b[39m\u001b[39m{\u001b[39;00mmemory\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtgt_mask \u001b[39m\u001b[39m{\u001b[39;00mtgt_mask\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdecode(ys, memory, tgt_mask)\n\u001b[1;32m     26\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m prob \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerator(out[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m/scratch/tb2817/1011_project/seq2seq_transformer.py:85\u001b[0m, in \u001b[0;36mSeq2SeqTransformer.decode\u001b[0;34m(self, tgt, memory, tgt_mask)\u001b[0m\n\u001b[1;32m     82\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoding(\n\u001b[1;32m     83\u001b[0m                   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtgt_tok_emb(tgt))\n\u001b[1;32m     84\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39membedding \u001b[39m\u001b[39m{\u001b[39;00membedding\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer\u001b[39m.\u001b[39;49mdecoder(embedding, memory,\n\u001b[1;32m     86\u001b[0m                   tgt_mask)\n",
      "File \u001b[0;32m/ext3/conda/1011_project/lib/python3.8/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1187\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ext3/conda/1011_project/lib/python3.8/site-packages/torch/nn/modules/transformer.py:293\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    290\u001b[0m output \u001b[39m=\u001b[39m tgt\n\u001b[1;32m    292\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 293\u001b[0m     output \u001b[39m=\u001b[39m mod(output, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[1;32m    294\u001b[0m                  memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[1;32m    295\u001b[0m                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[1;32m    296\u001b[0m                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask)\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m/ext3/conda/1011_project/lib/python3.8/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1187\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ext3/conda/1011_project/lib/python3.8/site-packages/torch/nn/modules/transformer.py:579\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    578\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask))\n\u001b[0;32m--> 579\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mha_block(x, memory, memory_mask, memory_key_padding_mask))\n\u001b[1;32m    580\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    582\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/ext3/conda/1011_project/lib/python3.8/site-packages/torch/nn/modules/transformer.py:596\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._mha_block\u001b[0;34m(self, x, mem, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mha_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, mem: Tensor,\n\u001b[1;32m    595\u001b[0m                attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 596\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultihead_attn(x, mem, mem,\n\u001b[1;32m    597\u001b[0m                             attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    598\u001b[0m                             key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    599\u001b[0m                             need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    600\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(x)\n",
      "File \u001b[0;32m/ext3/conda/1011_project/lib/python3.8/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1187\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ext3/conda/1011_project/lib/python3.8/site-packages/torch/nn/modules/activation.py:1155\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1145\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1146\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1152\u001b[0m         q_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_proj_weight, k_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_proj_weight,\n\u001b[1;32m   1153\u001b[0m         v_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj_weight, average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights)\n\u001b[1;32m   1154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1155\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1156\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1157\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1158\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1159\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1160\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1161\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask, need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1162\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask, average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights)\n\u001b[1;32m   1163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1164\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/ext3/conda/1011_project/lib/python3.8/site-packages/torch/nn/functional.py:5128\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[1;32m   5126\u001b[0m q \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(tgt_len, bsz \u001b[39m*\u001b[39m num_heads, head_dim)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m   5127\u001b[0m \u001b[39mif\u001b[39;00m static_k \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 5128\u001b[0m     k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39;49mcontiguous()\u001b[39m.\u001b[39;49mview(k\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], bsz \u001b[39m*\u001b[39;49m num_heads, head_dim)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m   5129\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5130\u001b[0m     \u001b[39m# TODO finish disentangling control flow so we don't do in-projections when statics are passed\u001b[39;00m\n\u001b[1;32m   5131\u001b[0m     \u001b[39massert\u001b[39;00m static_k\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m bsz \u001b[39m*\u001b[39m num_heads, \\\n\u001b[1;32m   5132\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpecting static_k.size(0) of \u001b[39m\u001b[39m{\u001b[39;00mbsz \u001b[39m*\u001b[39m num_heads\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00mstatic_k\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[26, 10, 30]' is invalid for input of size 202800"
     ]
    }
   ],
   "source": [
    "# run inference on the test set\n",
    "test_losses = []\n",
    "all_best_attn_labels = []\n",
    "all_preds_list = []\n",
    "all_labels_list = []\n",
    "raw_labels_list = []\n",
    "raw_source_list = []\n",
    "all_cleaned_preds_list = []\n",
    "all_bleu_1 = []\n",
    "all_bleu_2 = []\n",
    "all_bleu_3 = []\n",
    "all_bleu_4 = []\n",
    "all_meteor = []\n",
    "all_rouge_l = []\n",
    "with torch.no_grad():\n",
    "    for i, data in tqdm(enumerate(dataloaders['test']), leave=False):\n",
    "        # run evaluation on the test set\n",
    "        preds_list = []\n",
    "        labels_list = []\n",
    "        for j in range(len(data.source_vecs)):\n",
    "            pred = generate_question(seq2seq, data.source_data[j], vocab)\n",
    "            preds_list.append(pred)\n",
    "            labels_list.append(data.target_data[i])\n",
    "\n",
    "        # evaluate the predictions with the metrics\n",
    "        bleu_1, bleu_2, bleu_3, bleu_4, meteor, rouge_l = eval_metrics(preds_list, labels_list) # meteor, rouge_l\n",
    "        all_bleu_1.append(bleu_1)\n",
    "        all_bleu_2.append(bleu_2)\n",
    "        all_bleu_3.append(bleu_3)\n",
    "        all_bleu_4.append(bleu_4)\n",
    "        all_meteor.append(meteor)\n",
    "        all_rouge_l.append(rouge_l)\n",
    "\n",
    "        all_preds_list.append(preds_list)\n",
    "        all_labels_list.append(labels_list)\n",
    "        # all_cleaned_preds_list.append(cleaned_preds_list)\n",
    "        raw_labels_list.append(data.target_data)\n",
    "        raw_source_list.append(data.source_data)\n",
    "\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    avg_bleu_1 = np.mean(all_bleu_1)\n",
    "    avg_bleu_2 = np.mean(all_bleu_2)\n",
    "    avg_bleu_3 = np.mean(all_bleu_3)\n",
    "    avg_bleu_4 = np.mean(all_bleu_4)\n",
    "    # avg_meteor = np.mean(all_meteor)\n",
    "    # avg_rouge_l = np.mean(all_rouge_l)\n",
    "\n",
    "    print(f'Average Test Loss = {avg_test_loss}')\n",
    "    print(f'Average BLEU_1 Score = {avg_bleu_1}')\n",
    "    print(f'Average BLEU_2 Score = {avg_bleu_2}')\n",
    "    print(f'Average BLEU_3 Score = {avg_bleu_3}')\n",
    "    print(f'Average BLEU_4 Score = {avg_bleu_4}')\n",
    "    # print(f'Average METEOR Score = {avg_meteor}')\n",
    "    # print(f'Average ROUGE_L Score = {avg_rouge_l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source (Answer) Sentence:\t saint barthélemy , a volcanic island fully encircled by shallow reefs , has an area of 25 square kilometres -lrb- 9.7 sq mi -rrb- and a population of 9,035 -lrb- jan. 2011 estimate -rrb- .\n",
      "Target (Question) Label:\t what kind of island is st. barts ?\n",
      "Target (Question) Raw Prediction:\t is of the is the in ? <eos>\n",
      "\n",
      "Source (Answer) Sentence:\t emigrants from siberia that walked across the bering land bridge into north america may have had dogs in their company , and one writer suggests that the use of sled dogs may have been critical to the success of the waves that entered north america roughly 12,000 years ago , although the earliest archaeological evidence of dog-like canids in north america dates from about 9,400 years ago. :104 dogs were an important part of life for the athabascan population in north america , and were their only domesticated animal .\n",
      "Target (Question) Label:\t how old are the oldest findings of dogs in north america ?\n",
      "Target (Question) Raw Prediction:\t many did the first of of the of the ? ? <eos>\n",
      "\n",
      "Source (Answer) Sentence:\t those selected by the judges are sent to hollywood .\n",
      "Target (Question) Label:\t if contestants get approval from the judges , where do they go next ?\n",
      "Target (Question) Raw Prediction:\t is is the of the name of what is the the to of <eos>\n",
      "\n",
      "Source (Answer) Sentence:\t the lee strasberg theatre and film institute is in union square , and tisch school of the arts is based at new york university , while central park summerstage presents performances of free plays and music in central park .\n",
      "Target (Question) Label:\t in what new york park can one find performances at no cost ?\n",
      "Target (Question) Raw Prediction:\t what is is is is the name the in the the of <eos>\n",
      "\n",
      "Source (Answer) Sentence:\t johnson released `` as long as you love me '' as his coronation single while irene released `` we are one '' .\n",
      "Target (Question) Label:\t what song did caleb johnson first release after winning american idol ?\n",
      "Target (Question) Raw Prediction:\t is did the 's the <unk> to the ? ? ? <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out a few postprocesse predictions\n",
    "for i in range(5):\n",
    "    print('Source (Answer) Sentence:\\t', \" \".join(raw_source_list[0][i]))\n",
    "    print('Target (Question) Label:\\t', \" \".join(raw_labels_list[0][i]))\n",
    "    print('Target (Question) Raw Prediction:\\t', \" \".join(all_preds_list[0][i]))\n",
    "    # print('Target (Question) Postprocessed Prediction:', \" \".join(all_cleaned_preds_list[0][i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT TRAIN AND VAL LOSS\n",
    "import matplotlib.pyplot as plt \n",
    "def plot_over_training(per_epoch_metrics, title_name, subtitle_name, num_epochs):\n",
    "    t = np.arange(1, num_epochs+1)\n",
    "\n",
    "    fig, ax1 = plt.subplots(facecolor=(1, 1, 1))\n",
    "    colors = ['tab:blue', 'tab:red']\n",
    "    ax1.set_xlabel('epochs')\n",
    "    ax1.set_ylabel('loss')\n",
    "\n",
    "    for key, color in zip(per_epoch_metrics, colors):\n",
    "        label = f'{key}_loss'\n",
    "        ax1.plot(t, per_epoch_metrics[key], color=color, linewidth=1, label=label)\n",
    "\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.legend(loc='upper right')\n",
    "\n",
    "    fig.tight_layout\n",
    "    plt.suptitle(title_name, fontsize=14, y=1)\n",
    "    plt.title(subtitle_name, fontsize=10)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_over_training(plot_cache, 'Losses over 15 epochs', 'Model: Seq2seq Transformer', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d10e99a7d3ce7799ff53fffb01ded82fc9320fdeabd270dd8a29b265097acaf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
