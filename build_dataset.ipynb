{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.6.8 64-bit' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import time \n",
    "import json \n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, lil_tokens, max_vocab_size=10_000):\n",
    "        self.lil_tokens = lil_tokens\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.tokens = []\n",
    "        self.ids = {}\n",
    "\n",
    "        # add special tokens \n",
    "        self.tokens.append('<bos>')\n",
    "        self.tokens.append('<eos>')\n",
    "        self.tokens.append('<pad>')\n",
    "        self.tokens.append('<unk>')\n",
    "\n",
    "        # add all the tokens \n",
    "        self.build_vocab()\n",
    "    \n",
    "    def build_vocab(self):\n",
    "        all_tokens = [token for l_tokens in self.lil_tokens for token in l_tokens]\n",
    "        counter = Counter(all_tokens)\n",
    "        most_common = counter.most_common(self.max_vocab_size - len(self.tokens))\n",
    "        self.tokens += [item[0] for item in most_common]\n",
    "        self.ids = {token: id for id, token in enumerate(self.tokens)}\n",
    "\n",
    "    def get_id(self, w):\n",
    "        return self.ids[w]\n",
    "\n",
    "    def get_token(self, id):\n",
    "        return self.tokens[id]\n",
    "\n",
    "    def decode_idx2token(self, list_id):\n",
    "        return [self.tokens[i] for i in list_id]\n",
    "\n",
    "    def encode_token2idx(self, list_token):\n",
    "        return [self.ids[tok] if tok in self.ids else '<unk>' for tok in list_token]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "def load_qa_pairs(qa_pair_li):\n",
    "    answer_lil, question_lil = [], []\n",
    "    for qa in qa_pair_li:\n",
    "        answer_lil.append(qa[0])\n",
    "        question_lil.append(qa[1])\n",
    "\n",
    "    answer_vocab = Vocabulary(answer_lil, 45_000)\n",
    "    question_vocab = Vocabulary(question_lil, 28_000)\n",
    "\n",
    "    return answer_vocab, question_vocab\n",
    "\n",
    "\n",
    "class QAPair(Dataset):\n",
    "    def __init__(self, source, target):\n",
    "        pass \n",
    "\n",
    "    def __len__(self):\n",
    "        return \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<bos>', '<eos>', '<pad>', '<unk>', 'you', 'love', 'hate', 'i']\n",
      "{'<bos>': 0, '<eos>': 1, '<pad>': 2, '<unk>': 3, 'you': 4, 'love': 5, 'hate': 6, 'i': 7}\n",
      "[7, 5, 4, '<unk>', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "fake_data = [['i', 'love', 'you'], ['you', 'hate', 'me'], ['you', 'love', 'and', 'hate', 'him']]\n",
    "\n",
    "fake_vocab = Vocabulary(fake_data, 8)\n",
    "print(fake_vocab.tokens)\n",
    "print(fake_vocab.ids)\n",
    "print(fake_vocab.encode_token2idx(['i', 'love' , 'you', 'so', 'much']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_pairs = [\n",
    "    (['this', 'is', 'answer'], ['what', 'is', 'the', 'question']),\n",
    "    (['i', 'do', 'not', 'know'], ['when', 'are', 'assignments', 'over' ]),\n",
    "]\n",
    "\n",
    "ans_vocab, q_vocab = load_qa_pairs(fake_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos>',\n",
       " '<eos>',\n",
       " '<pad>',\n",
       " '<unk>',\n",
       " 'what',\n",
       " 'is',\n",
       " 'the',\n",
       " 'question',\n",
       " 'when',\n",
       " 'are',\n",
       " 'assignments',\n",
       " 'over']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_vocab.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
